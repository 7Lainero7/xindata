# Freelancer Earnings NLP System

## Описание

Прототип системы для анализа данных о доходах фрилансеров с возможностью отвечать на аналитические вопросы на естественном языке. В основе — локальная LLM (Llama/Mistral), преобразующая вопросы пользователя в SQL-запросы к базе данных, построенной на основе актуального датасета с Kaggle.

---

## Подход к решению

- **Автоматизация:** Система автоматически скачивает датасет с Kaggle и преобразует его в SQLite-базу.
- **NLP-интерфейс:** Для генерации SQL-запросов по пользовательским вопросам используется языковая модель (Llama/Mistral), работающая локально через llama-cpp-python.
- **CLI:** Вопросы задаются через консольный интерфейс, ответы выводятся в интерактивном режиме.
- **Контейнеризация:** Проект полностью запускается в Docker/Docker Compose, что обеспечивает воспроизводимость и простоту развертывания.

---

## Методы и технологии

- **Python 3.11** — основной язык разработки.
- **llama-cpp-python** — интеграция с Llama/Mistral для генерации SQL.
- **Pandas, SQLite** — обработка и хранение данных.
- **Click** — CLI-интерфейс.
- **Kaggle API** — автоматическая загрузка датасета.
- **Docker** — контейнеризация для удобства запуска.
- **Jupyter Notebook** — для EDA и валидации данных.

**Что сработало:**
- LLM хорошо справляется с простыми и средними аналитическими вопросами, если в prompt даны релевантные примеры.
- Автоматизация загрузки и подготовки данных ускоряет старт работы.

**Что не сработало:**
- LLM иногда генерирует неполные или некорректные SQL-запросы, особенно для сложных сравнительных вопросов или при недостатке примеров в prompt.
- Ограничение по длине prompt и max_tokens влияет на полноту ответа.

---

## Эффективность и точность

- **Точность**: Для типовых аналитических вопросов (агрегация, фильтрация, группировка) точность генерации SQL — 70–90% (по ручной проверке).
- **Скорость**: Время ответа — 5–15 секунд на вопрос (зависит от мощности CPU и размера модели).
- **Устойчивость**: Система корректно обрабатывает ошибки SQL и сообщает пользователю о некорректных запросах.

---

## Критерии оценки качества решения

- **Корректность SQL-ответов**: Система должна возвращать валидные SQL-запросы для большинства типовых вопросов.
- **Гибкость**: Возможность легко менять датасет, модель, структуру prompt.
- **Удобство запуска**: Всё работает из коробки через Docker или локально.
- **Качество кода**: Модули разделены по функциям, есть обработка ошибок, код читаемый и документированный.
- **Документация**: README содержит инструкции по запуску, описания подхода и критерии самооценки.

---

## Примеры вопросов

- Какой средний доход у фрилансеров из США?
- Сколько проектов в среднем выполняют специалисты уровня Beginner на платформе Fiverr?
- Какой способ оплаты наиболее часто используется фрилансерами из Азии?
- Как распределяется средний доход по категориям работ?
- Какой процент фрилансеров работает с клиентами из Европы?

---

## Самооценка

- **Код структурирован, покрывает все этапы: загрузка, подготовка, анализ, вывод.**
- **Подход обоснован: выбран LLM с few-shot prompt, что обеспечивает гибкость и расширяемость.**
- **Точность решения проверялась вручную на ряде вопросов, большинство SQL-запросов корректны.**
- **Система устойчива к ошибкам и легко масштабируется под другие датасеты.**

---

## Запуск

См. раздел "Быстрый старт" выше.
### 1. Клонируйте репозиторий

```sh
git clone https://github.com/7Lainero7/xindata.git
cd xindata
```

### 2. Установите зависимости

**Локально (Python 3.10+):**
```sh
python -m venv .venv
source .venv/bin/activate  # или .venv\Scripts\activate на Windows
pip install --upgrade pip
pip install -r requirements.txt
```

**Или через Docker:**
```sh
docker build -t freelance-llama .
docker run -it --rm -v $(pwd):/app freelance-llama
```
> **Примечание:** Если модель Llama большая, используйте volume для монтирования файла модели.

### 3. Скачайте модель Llama/Mistral

Модель будет скачана автоматически при первом запуске, если её нет в папке `models/`.  
Путь и URL модели можно изменить в `appdir/__init__.py` или `appdir/functions.py`.

### 4. Подготовьте kaggle.json

- Получите API-токен на [Kaggle](https://www.kaggle.com/settings/account) (Download API Token).
- Поместите файл `kaggle.json` в корень проекта или укажите путь в настройках.

### 5. Запуск CLI

```sh
python main.py
```

## Пример вопроса

- Насколько выше доход у фрилансеров, принимающих оплату в криптовалюте, по сравнению с другими способами оплаты?
- Как распределяется доход фрилансеров в зависимости от региона проживания?
- Какой процент фрилансеров, считающих себя экспертами, выполнил менее 100 проектов?
